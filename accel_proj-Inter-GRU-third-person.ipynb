{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f410da14-3615-4181-ae13-1e919d3f0ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:35:31.669004Z",
     "iopub.status.busy": "2025-04-23T20:35:31.668454Z",
     "iopub.status.idle": "2025-04-23T20:35:34.429923Z",
     "shell.execute_reply": "2025-04-23T20:35:34.429171Z",
     "shell.execute_reply.started": "2025-04-23T20:35:31.668982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.9.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.1.2)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93feca4d-9e9c-4d9b-9cf3-9b26045a6fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.2\n",
      "Num GPUs Available:  0\n",
      "TensorFlow is not using a GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 17:29:37.044858: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, Permute, Lambda, Multiply, Input, LayerNormalization, RepeatVector, Bidirectional, InputLayer, Conv1D, MaxPool1D, Conv2D, Conv3D, MaxPooling3D, BatchNormalization, MaxPool2D, GlobalMaxPool2D, GlobalAveragePooling2D, TimeDistributed, GRU, Dense, LSTM, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard \n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adadelta, Nadam, Adagrad\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit, TimeSeriesSplit, KFold, GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is using GPU:\", tf.test.gpu_device_name())\n",
    "else:\n",
    "    print(\"TensorFlow is not using a GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de01cc-e8d0-4400-9f00-cccf62663f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = ['Non-Func','Func']\n",
    "duration = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab6671-5b1b-45b3-bef0-26ca3abd296b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2 = regularizers.l2(l=1e-3)\n",
    "l1_l2 = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75469283-461a-4aa7-bcab-563bf9837774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_cnn2D(shape=(duration, 3, 1)):\n",
    "    opt = Adam(learning_rate=1e-3, clipvalue=0.5)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (2,2), padding='same', input_shape=shape),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(64, activation='relu', kernel_regularizer=l2\n",
    "             ),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, activation='relu', kernel_regularizer=l2\n",
    "             ),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(1, activation='sigmoid', kernel_regularizer=l2\n",
    "             )\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['binary_accuracy'], \n",
    "                  #sample_weight_mode=\"temporal\"\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a243a7-4dc1-4485-a8c8-39b04b2408f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "def cm(X, Y, model):\n",
    "    \n",
    "    #model = tf.keras.models.load_model(model_path, custom_objects={'leaky_relu': tf.nn.leaky_relu})\n",
    "    y_pred = model.predict(X)\n",
    "    #y_pred = y_pred.round()\n",
    "    y_pred = np.round(y_pred).tolist()\n",
    "    print(len(Y[Y==0]), len(Y[Y==1]), len(y_pred))\n",
    "    if (len(Y[Y==0])/len(Y) != 0) and (len(Y[Y==0])/len(Y) != 1):\n",
    "        cm = confusion_matrix(Y, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = class_labels)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        #Classification report\n",
    "        print('Classification Report')\n",
    "        print(classification_report(Y, y_pred, target_names = class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c88f55-ad04-40e6-95a8-8146c7f0cc5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the custom metrics and model building functions\n",
    "# Make sure to define functions like `build_improved_cnngru`, `f1_m`, `precision_m`, `recall_m`, `TP`, `TN`, `FP`, `FN`, `cm` as required.\n",
    "\n",
    "def create_model(x_0, y_0, z_0):\n",
    "    fullshape = (duration, 3)\n",
    "    train_accuracies = np.array([])\n",
    "    val_accuracies = np.array([])\n",
    "\n",
    "    sf = LeaveOneGroupOut()\n",
    "\n",
    "    for train_index, val_index in sf.split(x_0, y_0, z_0):\n",
    "\n",
    "        x_train, x_val = x_0[train_index], x_0[val_index]\n",
    "        y_train, y_val = y_0[train_index], y_0[val_index]\n",
    "        z_train, z_val = z_0[train_index], z_0[val_index]\n",
    "\n",
    "        # Debug unique groups in training and validation sets\n",
    "        print(\"Z train unique:\", np.unique(z_train))\n",
    "        print(\"Z val unique:\", np.unique(z_val))\n",
    "\n",
    "        # Reshape for scaling\n",
    "        x_train_reshaped = x_train.reshape(-1, x_train.shape[2])\n",
    "        x_val_reshaped = x_val.reshape(-1, x_val.shape[2])\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        x_train_reshaped = scaler.fit_transform(x_train_reshaped)\n",
    "        x_val_reshaped = scaler.transform(x_val_reshaped)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        x_train = x_train_reshaped.reshape(x_train.shape)\n",
    "        x_val = x_val_reshaped.reshape(x_val.shape)\n",
    "\n",
    "        print('Train: ', len(y_train[y_train==0]), len(y_train[y_train==1]))\n",
    "        print('Val: ', len(y_val[y_val==0]), len(y_val[y_val==1]))\n",
    "        #if np.unique(z_val) in [14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]:\n",
    "        \n",
    "        # Apply SMOTE to the training data\n",
    "        #smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        #x_train_reshaped = x_train.reshape(x_train.shape[0], -1)  # Reshape to 2D for SMOTE\n",
    "        #x_train_resampled, y_train_resampled = smote.fit_resample(x_train_reshaped, y_train)\n",
    "        #x_train = x_train_resampled.reshape(-1, fullshape[0], fullshape[1])  # Reshape back to 3D\n",
    "        #y_train = y_train_resampled\n",
    "\n",
    "        #print('Train: ', len(y_train[y_train==0]), len(y_train[y_train==1]))\n",
    "        #print('Val: ', len(y_val[y_val==0]), len(y_val[y_val==1]))\n",
    "\n",
    "        # Compute class weights\n",
    "        class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "        print(\"class weights: \", class_weights)\n",
    "        class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "        #modelts = build_improved_cnngru()\n",
    "        modelts = build_cnn2D()\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-9)\n",
    "        monitor = EarlyStopping(monitor='val_binary_accuracy', patience=20, mode='auto', restore_best_weights=True)\n",
    "\n",
    "        history = modelts.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=2,\n",
    "                              callbacks=[reduce_lr, monitor], epochs=100, batch_size=32, #class_weight=class_weights\n",
    "                             )\n",
    "\n",
    "        train_accuracy = modelts.evaluate(x_train, y_train, verbose=2)\n",
    "        train_accuracies = np.append(train_accuracies, train_accuracy[1])\n",
    "\n",
    "        val_accuracy = modelts.evaluate(x_val, y_val, verbose=2)\n",
    "        val_accuracies = np.append(val_accuracies, val_accuracy[1])\n",
    "\n",
    "        print(\"Z val: \", np.unique(z_val))\n",
    "        print(\"Train Acc: \", train_accuracy)\n",
    "        print(\"Val Acc:\", val_accuracy)\n",
    "\n",
    "        print('Confusion Matrix for Training')\n",
    "        cm(x_train, y_train, modelts)\n",
    "        print('Confusion Matrix for Validation')\n",
    "        cm(x_val, y_val, modelts)\n",
    "\n",
    "        plt.plot(history.history['binary_accuracy'], label='Training accuracy')\n",
    "        plt.plot(history.history['val_loss'], label='Validation accuracy')\n",
    "        plt.title('Training Acc vs. Validation Acc')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['loss'], label='Training loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "        plt.title('Training Loss vs. Validation Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Mean Training Accuracy:\", np.mean(train_accuracies))\n",
    "    print(\"Std Training Accuracy:\", statistics.pstdev(np.asarray(train_accuracies)))\n",
    "\n",
    "    print(\"Mean Validation Accuracy:\", np.mean(val_accuracies))\n",
    "    print(\"Std Validation Accuracy:\", statistics.pstdev(np.asarray(val_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6194a-ac25-4056-b726-83e5d2b56602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4899e129550b3c63015e5cf3cd0c1deb5cd9aba9e7bcb8eea38a6da82e14ed3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
